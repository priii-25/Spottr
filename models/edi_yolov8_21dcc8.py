# -*- coding: utf-8 -*-
"""EDI_YOLOV8 21dcc8

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/priyanshii11/edi-yolov8-21dcc8.82fc92e2-f8fb-49f2-a6a8-2ad7fa66c483.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20251105/auto/storage/goog4_request%26X-Goog-Date%3D20251105T231345Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D54b68f4c2b1e62afac067751aa7d51db14944ae28291eee952d30b0599a9d5b8abe891f89ab57c3b99cc9f1672868fc3ff1229fd313cccade87c75cb2810e154439920b44691cca1183dc8539c60b4bc2d2b0811250ce9558c2ce0f22d6666fd945dccb7664eda8829c78f6ba31ec6d962abeb56bdc71a991724a78c79bd835b2f5bfb7546c6431dd2ffccd08a60885f654c21c88d7eb743ff3e798593f21290a018a9aee2149faee8d2f0521afa0cc46e607dda8ae7a9fbecb163d919f7c94c18fc0a234a2ac837cd7d8f50e5b61df56afa2c084be5c882060361ee1773a7225fe5192b433001acb346cb6f040ffe5e813b1d02354a91fe960ba83a6a41e7a0
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
rohitsuresh15_radroad_anomaly_detection_path = kagglehub.dataset_download('rohitsuresh15/radroad-anomaly-detection')

print('Data source import complete.')

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

!nvidia-smi

pip install ultralytics

import os
HOME = os.getcwd()
print(HOME)

from IPython import display
display.clear_output()

import ultralytics
ultralytics.checks()

!pip install opencv-python-headless

pip install -U ipywidgets

"""# **Training the model**"""

import ultralytics
from ultralytics import YOLO

# Define the path to the data.yaml file
data_yaml_path = '/kaggle/input/radroad-anomaly-detection/images/data.yaml'

# Initialize the model
model = YOLO('yolov8n.pt')  # Using the Nano model for lower memory usage

# Train the model
# model.train(data=data_yaml_path, epochs=150, imgsz=900, batch=8)
# Initial training with smaller image size
model.train(data=data_yaml_path, epochs=40, imgsz=640, batch=8, save_period=5)

# Continue training with larger image size
model.train(data=data_yaml_path, epochs=35, imgsz=960, batch=8, save_period=5)

# Final training with original image size
model.train(data=data_yaml_path, epochs=25, imgsz=1280, batch=8, save_period=5)

"""**Listing stored files after training - graphs**"""

!ls /kaggle/working/runs/detect/train
print()
!ls /kaggle/working/runs/detect/train2
print()
!ls /kaggle/working/runs/detect/train22

from IPython.display import Image, display

# Display confusion matrix for image size 640, epoch 40
display(Image(filename='runs/detect/train/confusion_matrix.png', width=600))
print('Confusion matrix - image size 640, epoch 40')
print()

# Display confusion matrix for image size 960, epoch 35
display(Image(filename='runs/detect/train2/confusion_matrix.png', width=600))
print('Confusion matrix - image size 960, epoch 35')
print()

# Display confusion matrix for image size 1280, epoch 25
display(Image(filename='runs/detect/train22/confusion_matrix.png', width=600))
print('Confusion matrix - image size 1280, epoch 25')
print()

# Image(filename='runs/detect/train2/results.png',width=600)
from IPython.display import Image, display

# Display for image size 640, epoch 40
display(Image(filename='runs/detect/train/results.png', width=600))
print('image size 640, epoch 40')
print()

# Display for image size 960, epoch 35
display(Image(filename='runs/detect/train2/results.png', width=600))
print('image size 960, epoch 35')
print()

# Display for image size 1280, epoch 25
display(Image(filename='runs/detect/train22/results.png', width=600))
print('image size 1280, epoch 25')
print()

# Image(filename='runs/detect/train2/val_batch0_pred.jpg',width=600)

# Display for image size 640, epoch 40
display(Image(filename='runs/detect/train/val_batch0_pred.jpg', width=600))
print('image size 640, epoch 40')
print()

# Display for image size 960, epoch 35
display(Image(filename='runs/detect/train2/val_batch0_pred.jpg', width=600))
print('image size 960, epoch 35')
print()

# Display for image size 1280, epoch 25
display(Image(filename='runs/detect/train22/val_batch0_pred.jpg', width=600))
print('image size 1280, epoch 25')
print()

"""# Validating"""

# import ultralytics
# from ultralytics import YOLO

!yolo task=detect mode=val model=runs/detect/train/weights/best.pt data=/kaggle/input/radroad-anomaly-detection/images/data.yaml
print()

!yolo task=detect mode=val model=runs/detect/train2/weights/best.pt data=/kaggle/input/radroad-anomaly-detection/images/data.yaml
print()

!yolo task=detect mode=val model=runs/detect/train22/weights/best.pt data=/kaggle/input/radroad-anomaly-detection/images/data.yaml
print()

"""# Prediction"""

!yolo task=detect mode=predict model=runs/detect/train/weights/best.pt conf=0.25 source=/kaggle/input/radroad-anomaly-detection/images/test/images
print()

!yolo task=detect mode=predict model=runs/detect/train2/weights/best.pt conf=0.25 source=/kaggle/input/radroad-anomaly-detection/images/test/images
print()

!yolo task=detect mode=predict model=runs/detect/train22/weights/best.pt conf=0.25 source=/kaggle/input/radroad-anomaly-detection/images/test/images
print()

"""# Testing on video feed"""

# import cv2
# from ultralytics import YOLO

# model = YOLO('/kaggle/working/runs/detect/train2/weights/best.pt')  # Load your trained model

# cap = cv2.VideoCapture(0)  # Change the index if you have multiple cameras

# while True:
#     ret, frame = cap.read()
#     if not ret:
#         break

#     results = model(frame)  # Perform detection
#     annotated_frame = results.render()[0]  # Annotate frame

#     cv2.imshow('YOLOv8 Detection', annotated_frame)
#     if cv2.waitKey(1) & 0xFF == ord('q'):
#         break

# cap.release()
# cv2.destroyAllWindows()



import cv2
from ultralytics import YOLO
import matplotlib.pyplot as plt
from IPython.display import display, clear_output

# Load your trained YOLO model
model = YOLO('/kaggle/working/runs/detect/train/weights/best.pt')  # Replace with your actual model path

# Use a video file instead of a webcam
video_path = '/kaggle/input/radroad-anomaly-detection/videos_without_audio/10th July-20231125T045234Z-001/10th July/111_10-07-2023.mp4'  # Replace with your actual video file path
cap = cv2.VideoCapture(video_path)

# Get the video's width, height, and FPS
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = int(cap.get(cv2.CAP_PROP_FPS))

# Define the codec and create a VideoWriter object to save the output video
output_path = '/kaggle/working/runs/detect/train/output_video.mp4'
out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))

if not cap.isOpened():
    print("Error: Could not open video file")
else:
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        results = model(frame)  # Perform detection

        # Annotate frame manually
        for result in results:
            for box in result.boxes:
                # Extract the bounding box coordinates
                x1, y1, x2, y2 = box.xyxy[0].tolist()
                conf = box.conf[0]  # Confidence score
                cls = int(box.cls[0])  # Class label

                # Draw the bounding box on the frame
                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)
                label = f'{model.names[cls]} {conf:.2f}'
                cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)

        # Write the annotated frame to the output video
        out.write(frame)

    cap.release()
    out.release()
    print(f"Output video saved as '{output_path}'")

